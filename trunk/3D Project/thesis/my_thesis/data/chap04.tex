
%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 

\chapter{解码器单核性能优化}
\label{cha:singlecoreopt}

按照\refsec{sec:optapproach}中提到的优化方案，我们对解码器的单核性能进行了若干优化。本章中列举其中具代表意义的部分。

\refsec{sec:singlecorelogicopt}详细介绍了对函数逻辑的优化，\refsec{sec:singlecoreloopopt}介绍了对循环的优化并举例说明，\refsec{sec:singlecoreasmopt}介绍了汇编优化，\refsec{sec:singlecoreothers}提及了其他一些优化。

\section{函数逻辑优化}
\label{sec:singlecorelogicopt}

在MVCCommonLib模块中，PBPridict.cpp文件中包含了一些宏块预测相关的函数。此前的性能分析结果\autoref{tab:vs10}中显示，其中的macroblockGetHalfPel()函数耗时较多。这是一个使用Finite Impulse Response（FIR）计算一个Luma块的half-pel的函数。具体算法参考了《H.264 and MPEG-4 video compression, video coding for next-generation multimedia》\cite{richardson2003h}第173页起的瞄述。

函数内的一部分源代码如下：
\begin{lstlisting}[caption = {macroblockGetHalfPel()函数片段（优化前）}, label = lst:macroblockGetHalfPelorig]
`\dots`
for (int i = 0; i < hw; ++i){
	for (int j = 2; j < hh - 3; ++j){
		pif->vdata_half[0][i][j] = `\dots`; //some expression of vdata_half[][][] and vdata[][]
	}
}
for (int i = 0; i < hw; ++i){
	for (int j = 2; j < hh - 3; ++j){
		tmp[i][j] = `\dots`; //some expression of vdata[][]
	}
}
`\dots`
\end{lstlisting}

检查两次循环中对变量的访问，第二次循环需要访问vdata数组，而第一次循环只修改vdata\_half数组，对vdata没有做任何改动，所以两个循环可以合并成一个。

最后形成的代码如下：

\begin{lstlisting}[caption = {macroblockGetHalfPel()函数片段（优化后）}, label = lst:macroblockGetHalfPelopt]
`\dots`
for (int i = 0; i < hw; ++i)
	for (int j = 2; j < hh - 3; ++j){
		pif->vdata_half[0][i][j] = `\dots`; //some expression of vdata_half[][][] and vdata[][]
		tmp[i][j] = `\dots`; //some expression of vdata[][]
	}
`\dots`
\end{lstlisting}

这个优化使程序运行时间\footnote{这里所说的程序运行时间是指用release版本的解码器解码一个长度为65帧，分辨率为$720\times576$，路数为2的Multi-view视频所耗费的时间。下同。}缩短了1016ms\footnote{原始的版本总运行时间为26344ms。}。

同样在MVCCommonLib模块中的PBPridict.cpp里，macroblockPredGetDataY()和macroblockPredGetDataUV()函数也是运行耗时很多的函数，事实上，不论是Visual Studio还是VTune的分析结果，这两个函数都是占用时间最多的（见\autoref{tab:vs10}和\autoref{tab:vtune10}）。

这两个函数大部分的时间耗费在memset和memcpy上。对于这些系统api的调用，我们无法作修改，但是仔细观察其逻辑，我们发现函数的逻辑判断结构可以做一定优化。

源代码如下：

\begin{lstlisting}[caption = {macroblockPredGetDataY()函数片段（优化前）}, label = lst:macroblockPredGetDataYorig]
`\dots`
if (x<0) x = 0;
if (x >= pif->sizeh) x = pif->sizeh - 1;
`\dots`
if (le < 0) le = 0;
if (le > 0)
	memcpy(pif->vdata[i]+dl, linef + sl, le);`\label{line:memcpy}`
`\dots`
\end{lstlisting}

由于pif->sizeh的物理意义决定了它必然是非负的，当x=0的时候不可能出现x>=pif->sizeh的情况，所以每次调用macroblockPredGetDataY()的时候，如果x<0，都做了多余判断。

le是int类型，所以当le<0时，顺序执行语句不可能出现le>0的情况，也存在多余判断问题。事实上，第\ref{line:memcpy}行的memcpy语句只有在le>=1的情况下才会执行，而当le<1时，le都会被赋值为0。

经过优化后的代码如下：

\begin{lstlisting}[caption = {macroblockPredGetDataY()函数片段（优化后）}, label = lst:macroblockPredGetDataYopt]
`\dots`
if (x<0) x = 0;
else if (x >= pif->sizeh) x = pif->sizeh - 1;
`\dots`
if (le < 1) le = 0;
else
	memcpy(pif->vdata[i]+dl, linef + sl, le);
`\dots`
\end{lstlisting}

对macroblockPredGetDataUV()的优化同理。这两个函数优化后，程序运行时间再次减少了437ms。

在macroblockGetPred\_axb()中，原始的程序一共用了超过20个if语句来决定如何进行预测。根据我在《数字逻辑设计》以及《计算机组成原理》课程中的实验经验，这样的多重if语句用switch语句替换不但能使代码逻辑更加清晰，而且能提高性能。这相当于是把许多串联的2位的MUX改写成一个多位的MUX。

此处优化使程序运行时间缩短了47ms。

\section{循环优化}
\label{sec:singlecoreloopopt}

% macroblockGetPred_axb 1031ms
macroblockGetPred\_axb()函数耗时在\autoref{tab:vs10}和\autoref{tab:vtune10}中分别列在第4和第5位，也是耗时极多的函数。除了上一节提到的if语句改写成switch语句之外，我们还对其进行了循环内部的优化。

% 循环变量的声明
首先是循环变量的声明，根据我们的经验，编译器会对循环变量的声明放在循环体内部的写法做优化，至少在linux平台下的gcc会这样做。再加上将循环变量的声明放在循环内部可以避免变量在作用域之外被使用，所以我们将所有的循环变量声明全部移到循环体内部。

其次，我们观察代码发现有多处如\autoref{lst: macroblockGetPred_axborig}所示的循环。

\begin{lstlisting}[caption = {macroblockGetPred\_axb()函数片段（优化前）}, label = lst: macroblockGetPred_axborig]
`\dots`
for (i = 0; i < sizex; ++i)
	for (j = 0; j < sizey; ++j)
		pred->y[i+off_in_x][j+off_in_y] = pif->vdata_half[halfid][i+borderT][j+borderL];`\label{line:index}`
`\dots`
\end{lstlisting}

这些循环内的操作有一个特点：使用包含循环变量的表达式作为数组访问的下标。

以\autoref{lst: macroblockGetPred_axborig}中第\ref{line:index}行为例，在整个循环中，计算了$sizex\times sizey$次$i+off\_in\_x$和$i+borderT$。实际上可以在内层循环外就进行计算，这样就只用计算$sizex$次，极大地减少了加法操作，同时大幅减少了变量访问次数：本来要访问两个变量，放在寄存器中，再做加法；现在只用访问一个计算好的变量即可。

优化后的代码如下：
\begin{lstlisting}[caption = {macroblockGetPred\_axb()函数片段（优化后）}, label = lst: macroblockGetPred_axbopt]
`\dots`
for (int i = 0; i < sizex; ++i){
	int ioffinx = i+off_in_x;
	int iboarterT = i+borderT;
	for (int j = 0; j < sizey; ++j)
		pred->y[ioffinx][j+off_in_y] = pif->vdata_half[halfid][iboarterT][j+borderL];
}
`\dots`
\end{lstlisting}

经过上述优化，程序运行时间缩短了1031ms。

% 循环内外层对cache的优化

\section{汇编优化}
\label{sec:singlecoreasmopt}

%此处说idct8x8
我们查找了一些文献，发现可以用MMX和SSE等扩展指令集来加速一些矩阵变换函数，例如idct8x8。
Intel Application Note AP-922\cite{intel-ap922}说明了如何用MMX和SSE加速DCT变换。AP-945\cite{intel-ap945}说明了如何用SSE2加速IDCT变换。

实际操作中，我们采用了Laurent Aimar、Loren Merritt、Holger Lubitz和Min Chen编写的SSE2-optimized H.264 iDCT代码替换C++实现的iDCT代码。

由于我们测试用的样例视频对idct8x8的使用远不及idct4x4频繁，所以这部分优化在程序运行时间上并没有明显的体现。这是由于我们目前主要测试的是H.264的Base Profile，当我们的解码器将来支持High Profile的时候，就会大量调用8x8的变换了。

\section{其他优化}
\label{sec:singlecoreothers}

% 内容相关的判断顺序微调
除了以上优化之外，我们还进行了一些细微的优化。

在每一路H.264码流的解码过程中，我们经常需要判断一些标志位的值，根据这些标志位来选择做什么样的操作。这往往是通过一系列的if-else判断实现的。这就出现了很多的选择分支，进入每个分支的概率是不同的。我们通过解码大量不同的视频文件，记录这些分支的选择情况，对判断的顺序进行了微调。将大概率的事件优先判断，执行相应的操作，省去了一些在进入分支之前的无效判断。

这样的优化对所有的测试样例平均提高1\%的性能。

% 编译器ICC
我们还尝试了更换编译器，使用Intel C++ Compiler Professional（见\refsec{sec:platformdesc}）来替换Visual Studio包含的编译器。

用ICC编译的代码比VS默认编译器编译出来的代码快5\%到6\%。

\section{小结}
\label{sec:sum4}
本章主要介绍了对解码器进行优化，包括逻辑重构、循环优化、汇编优化以及其他（例如编译器）的优化。这些优化主要提高了单核解码性能。尽管有了这些优化，解码器的单核性能仍然不能满足需求，所以还需要做并行化，这一部分在下一章中展开。

\cleardoublepage
